# ğŸ§  AI Intel Digest

**AI Intel Digest** is a privacy-first, fully local AI system that automatically collects, evaluates, summarizes, and delivers **daily AI / GenAI news and product ideas** directly to Telegram.

No cloud LLM APIs.  
No tracking.  
Runs entirely on your machine using **Ollama + local models**.

---

## âœ¨ What It Does

AI Intel Digest runs as a daily pipeline:

1. Collects fresh AI-related content (currently Hacker News)
2. Filters low-signal items
3. Deduplicates similar stories using embeddings + FAISS
4. Evaluates relevance using a local LLM
5. Builds structured digests (JSON + Markdown)
6. Sends a clean, engaging summary to Telegram

You open Telegram â†’ you get the signal â†’ no scrolling required.

---

## ğŸ§© Features

### ğŸ  Fully Local AI
- Uses **Ollama** (Gemma, LLaMA, etc.)
- No OpenAI / Anthropic / external APIs
- All processing happens on your machine

### ğŸ§  Multi-Persona Intelligence
Supported personas:
- **GENAI_NEWS** â€“ AI / GenAI engineering updates
- **PRODUCT_IDEAS** â€“ reusable product & startup ideas

Each persona has:
- Custom LLM prompts
- Structured JSON schema validation
- Independent scoring & filtering

### ğŸ” Smart Filtering & Deduplication
- Time-window based â€œtrue dailyâ€ digests
- Vector embeddings with **FAISS**
- Prevents repeated or near-duplicate items

### ğŸ“Š Signal-Aware Ranking
- Includes **Hacker News upvotes & comment counts**
- Sorts by relevance + engagement
- Highlights top picks first

### ğŸ§¾ Digest Outputs
- JSON (machine-readable)
- Markdown (human-readable)
- Stored locally for history & auditing

### ğŸ“¬ Telegram Delivery
- MarkdownV2-safe formatting
- â€œWhy it mattersâ€ summaries
- Tags, audience hints, and engagement signals
- Single combined daily message


## ğŸ—ï¸ Architecture

Ingestion â†’ Prefilter â†’ Dedup (FAISS)
â†’ LLM Evaluation (Ollama)
â†’ Digest Builder (JSON/MD)
â†’ Telegram Delivery

## ğŸ§  Models

- **LLM**: `gemma3:12b` (default, configurable)
- **Embeddings**: `nomic-embed-text`
- Easily switchable via `.env`

## ğŸ“ Project Structure

ai-intel-digest/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ cli/ # CLI entrypoints
â”‚ â”œâ”€â”€ config/ # Pydantic settings
â”‚ â”œâ”€â”€ db/ # SQLAlchemy models
â”‚ â”œâ”€â”€ services/
â”‚ â”‚ â”œâ”€â”€ hn_ingest.py # Hacker News ingestion
â”‚ â”‚ â”œâ”€â”€ evaluator.py # LLM evaluators
â”‚ â”‚ â”œâ”€â”€ dedup.py # FAISS deduplication
â”‚ â”‚ â””â”€â”€ telegram_delivery.py
â”‚ â””â”€â”€ workflows/
â”‚ â”œâ”€â”€ run_digest.py
â”‚ â””â”€â”€ build_digest.py
â”œâ”€â”€ out/ # Generated digests
â”œâ”€â”€ data/ # SQLite DB
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš™ï¸ Setup

### 1ï¸âƒ£ Requirements
- Python **3.11+**
- Ollama installed and running
- Telegram bot token

### 2ï¸âƒ£ Install
```bash
git clone https://github.com/yourusername/ai-intel-digest.git
cd ai-intel-digest
python -m venv .venv
source .venv/bin/activate  # Windows: .\.venv\Scripts\Activate.ps1
pip install -r requirements.txt

3ï¸âƒ£ Pull Models
ollama pull gemma3:12b
ollama pull nomic-embed-text

4ï¸âƒ£ Configure Environment
cp .env.example .env


Example .env:

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:12b

PERSONA_GENAI_NEWS_ENABLED=true
PERSONA_PRODUCT_IDEAS_ENABLED=true

TIME_WINDOW_HOURS=24
EVAL_MAX_ITEMS=10

OLLAMA_EMBED_MODEL=nomic-embed-text
DEDUP_SIM_THRESHOLD=0.86

TELEGRAM_ENABLED=true
TELEGRAM_BOT_TOKEN=YOUR_BOT_TOKEN
TELEGRAM_CHAT_ID=YOUR_CHAT_ID
TELEGRAM_PARSE_MODE=MarkdownV2
TELEGRAM_MAX_ITEMS=6

â–¶ï¸ Usage
Run Manually
python -m src.cli.main run

Health Check
python -m src.cli.main doctor

â° Automation
Windows (Task Scheduler)

Trigger: Daily

Action:

Program: powershell.exe
Arguments:
  -Command "cd C:\path\to\ai-intel-digest; .\.venv\Scripts\Activate.ps1; python -m src.cli.main run"

